---
title: Cross-Entropy Loss là gì?
excerpt: "This post reviews some extremely remarkable results in applying deep neural networks to natural language processing (NLP)"
date: 2017-07-07
layout: post
comments: true
---
<!-- tags: 
  - neural networks
  - deep learning
  - representations
  - NLP
  - recursive neural networks
  - rnn -->

# Cross-Entropy Loss là gì?

{: class="table-of-content"}
* TOC
{:toc}

## Contents

<a id="introduction"></a>
## Introduction

<div class="imgcap">
	<img src="/assets/images/ce_post/shanon-entropy.jpeg" alt="" style="width:350px; height:250px;">
	<div class="thecap" style="font-size: 15px;">Giai thoại Neumann-Shannon (From <a href="http://www.eoht.info/page/Neumann-Shannon+anecdote">Hmopedia</a>)</div>
</div>
<div class="spaceafterimg"></div>
